---
title: "STA130 Rstudio Homework"
author: "[Student Name] ([Student Number]), with Josh Speagle & Scott Schwartz"
subtitle: Problem Set 7
urlcolor: blue
output:
  pdf_document: default
---

```{r, include=FALSE}
knitr::opts_chunk$set(eval=TRUE, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE)
```

# Instructions

Complete the exercises in this `.Rmd` file and submit your `.Rmd` and knitted `.pdf` output through [Quercus](https://q.utoronto.ca/courses/296457) by 11:59 pm E.T. on Thursday, March 16.

```{r, message=FALSE}
library(tidyverse)
```

# Question 1: Multivariate Linear Regression and Mario Kart

In this question, you will revisit the Mario Kart data we looked at in this week's class. This data set contains eBay sales of the game Mario Kart for Nintendo Wii in October 2009 and is available in the `openintro` R package. We have provided a local csv copy, which we will load in below.

```{r}
# load in data
mariokart <- read_csv("mariokart.csv")
glimpse(mariokart)
```

Based on documentation in the data set, there are a handful of very high-priced items that were actually bundles of several games/items rather than just Mario Kart. Let's now filter these out.

```{r}
# filter out bundles
mariokart2 <- 
  mariokart %>% 
  filter(total_pr < 100)
glimpse(mariokart2)
```

\
**(a)** Sellers on eBay have the option to include a stock photo as the illustration of the product for sale. Does this choice affect the selling price? Carry out a **univariate (single-variable) linear regression analysis** and predict the mean selling price of the `total_pr` variable for sellers who do and do not use stock photos (`stock_photo`). 

*Hint: Your code from Question 4d in HW6 might be helpful here.* 
    
```{r}
mean(predict(lm(total_pr ~ stock_photo, data = mariokart2)))

```

> *47.43191*

\
**(b)** Sellers are rated by buyers on eBay, captured in the variable `seller_rating`. To simplify our analysis, we will categorize sellers by whether their rating is "low", "medium", or "high". Using `mutate()` and `case_when()`, create a new variable called `seller_rating_tier` that is "low" if `seller_rating <= 200`, "medium" if `200 < seller_rating <= 4500`, and "high" if `seller_rating > 4500`. Then, carry out a **linear regression analysis** to predict `total_pr` for the "low", "medium", and "high" levels of the new `seller_rating_tier` variable.

*Hint: The syntax `lm(y ~ x)` will still work even if `x` is a multi-valued categorical explanatory variable.*

```{r}
mariokart3 <- mutate(mariokart2, seller_rating_tier = case_when(
seller_rating <= 200 ~ "low",
seller_rating > 200 & seller_rating <= 4500 ~ "medium",
seller_rating > 4500 ~ "high",
TRUE ~ "F"
))
mariokart3
mean(predict(lm(mariokart3$total_pr ~ mariokart3$seller_rating_tier)))
summary(lm(mariokart3$total_pr ~ mariokart3$seller_rating_tier))


```

> *47.43191*

How many indicator variables are in the model? Describe these indicator variables. Which seller rating group is `lm()` treating as the baseline category?
    
> *There are 2, condition and stock photo. The baseline category is high*

\
**(c)** Create **boxplots** of `total_pr` for each category of seller based on `seller_rating_tier`.

```{r}
mariokart3 %>%
  ggplot(aes(x = seller_rating_tier, y = total_pr)) + geom_boxplot()

```

Is this visualization consistent with your estimates from above? Why or why not might this be the case?

> *Pretty consistent as the ordering by price makes sense here. The outliers are a bit strange, however as I don't understand how that can happen here.*

\
**(d)** Now, perform an appropriate **multivariate regression analysis** including **interaction terms** to examine whether `seller_rating_tier` has an effect on the relationship between `total_pr` and `duration`.

Note that the full regression model here is:

\begin{align*}
\texttt{total\_pr}_i = {} & \beta_0 + \beta_1 \times \texttt{seller\_tier\_low}_i + \beta_2 \times \texttt{seller\_rating\_tier\_medium}_i + \beta_3 \times \texttt{duration}_i \\
{} & + \beta_4 \times \texttt{seller\_rating\_tier\_low}_i \times \texttt{duration}_i + \beta_5 \times \texttt{seller\_rating\_tier\_medium}_i \times \texttt{duration}_i \\
{} & + \epsilon_i
\end{align*}

*Hint: The syntax for a multivariate interaction model is `lm(y ~ x1 + x2 + x1 * x2)`.*

```{r}
mariokart3$medium <- ifelse(mariokart3$seller_rating_tier == "medium", 1, 0)
mariokart3$low <- ifelse(mariokart3$seller_rating_tier == "low", 0, 1)
lm(total_pr ~ duration + seller_rating_tier+ seller_rating_tier * duration, data = mariokart3)

```

What is the equation of the fitted regression line for sellers with low ratings?

> *lm(total_pr ~ duration + seller_rating_tier0,1+ seller_rating_tier * duration, data = mariokart3)*

What is the equation of the fitted regression line for sellers with medium ratings?

> *lm(total_pr ~ duration + seller_rating_tier1,0+ seller_rating_tier*

What is the equation of the fitted regression line for sellers with high ratings?

> *lm(total_pr ~ duration + seller_rating_tier0,0+ seller_rating_tier*
     
\
**(e)** Produce an appropriate plot to visualize the fitted relation.

*Hint: Your code from Problem 2d in HW6 might prove useful here.*

```{r}
#ggplot(mariokart3) + aes(x = (duration + seller_rating_tier+ seller_rating_tier * duration), y =total_pr) + facet_wrap(~seller_rating_tier) + geom_point() + geom_smooth(method = lm, se = FALSE)

```

Does the seller rating tier appear to modify the association between duration and total price? Write 1-2 sentences explaining your answer.

> *REPLACE THIS TEXT WITH YOUR ANSWER*


# Question 2: Predictions and Model Comparison

\
**(a)** Divide the data into **testing** and **training** data sets that include 30\% and 70\% of the data, respectively. Then, fit multivariate linear regression models for the total price `total_pr` using the following combinations of variables (**"features"**) as predictors with training data only:

i. `stock_photo`

ii. `stock_photo`, `duration`, and their interaction

iii. `seller_rating`

iv. `stock_photo`, `seller_rating`, and their interaction

v. `stock_photo`, `seller_rating`, `duration`, and all interaction terms

*Hint: There are a number of approaches for computing the training/testing splits here. One possibility is you can random sample some fraction `X` of the input data using the `sample_frac()` function and then subsequently select the remaining data that has not been sampled using the `anti_join()` function.*

```{r}
set.seed(130) # use this seed to make your analysis reproducible

dataset <- mariokart3

# Divide the dataset into training and testing sets
training_indices <- sample(nrow(dataset), round(0.7 * nrow(dataset)), replace = FALSE)
train <- dataset[training_indices, ]
test <- dataset[-training_indices, ]
model1 <- lm(total_pr ~ stock_photo, data = train)
model2 <- lm(total_pr ~ stock_photo * duration, data = train)
model3 <- lm(total_pr ~ seller_rating, data = train)
model4 <- lm(total_pr ~ stock_photo * seller_rating, data = train)
model5 <- lm(total_pr ~ stock_photo * seller_rating * duration, data = train)


```

\  
**(b)** Calculate the **root-mean-square-error (RMSE)** for each of the five models from part (a) over both the training and testing datasets (10 values in total) and save the results in a tibble with columns named `model`, `rmse_train`, and `rmse_test`. 

As a reminder, for a given response with observed values $y_1,\dots,y_n$ and corresponding predicted values (from the above models) of $\hat{y}_1,\dots,\hat{y}_n$, the RMSE is defined as:

$$ {\rm RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)} $$

*Hint: You can use the syntax `train_linear_model %>% predict(test_data)` to generate predictions to new data values. You can also store your models in a list using the syntax `list(model1, model2, ...)` and access them using the syntax `list[[i]]`.*

```{r}
rmse_list <- list()

# Create a function to calculate the RMSE
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

# Model 1: stock_photo
# Train the model
model1 <- lm(total_pr ~ stock_photo, data = train)
# Calculate the RMSE for the training data
rmse_train1 <- rmse(train$total_pr, predict(model1, newdata = train))
# Calculate the RMSE for the testing data
rmse_test1 <- rmse(test$total_pr, predict(model1, newdata = test))
# Store the results in the list
rmse_list[[1]] <- c("Model 1", rmse_train1, rmse_test1)

# Model 2: stock_photo, duration, and interaction
# Train the model
model2 <- lm(total_pr ~ stock_photo * duration, data = train)
# Calculate the RMSE for the training data
rmse_train2 <- rmse(train$total_pr, predict(model2, newdata = train))
# Calculate the RMSE for the testing data
rmse_test2 <- rmse(test$total_pr, predict(model2, newdata = test))
# Store the results in the list
rmse_list[[2]] <- c("Model 2", rmse_train2, rmse_test2)

# Model 3: seller_rating
# Train the model
model3 <- lm(total_pr ~ seller_rating, data = train)
# Calculate the RMSE for the training data
rmse_train3 <- rmse(train$total_pr, predict(model3, newdata = train))
# Calculate the RMSE for the testing data
rmse_test3 <- rmse(test$total_pr, predict(model3, newdata = test))
# Store the results in the list
rmse_list[[3]] <- c("Model 3", rmse_train3, rmse_test3)

# Model 4: stock_photo, seller_rating, and interaction
# Train the model
model4 <- lm(total_pr ~ stock_photo * seller_rating, data = train)
# Calculate the RMSE for the training data
rmse_train4 <- rmse(train$total_pr, predict(model4, newdata = train))
# Calculate the RMSE for the testing data
rmse_test4 <- rmse(test$total_pr, predict(model4, newdata = test))
# Store the results in the list
rmse_list[[4]] <- c("Model 4", rmse_train4, rmse_test4)

# Model 5: all predictors and interactions
# Train the model
model5 <- lm(total_pr ~ stock_photo * seller_rating * duration, data = train)
# Calculate the RMSE for the training data
rmse_train5 <- rmse(train$total_pr, predict(model5, newdata = train))
# Calculate the RMSE for the testing data
rmse_test5 <- rmse(test$total_pr, predict(model5, newdata = test))
# Store the results in the list
rmse_list[[5]] <- c("Model 5", rmse_train5, rmse_test5)

# Combine the results into a tibble
rmse_df <- as.data.frame(do.call(rbind, rmse_list))
names(rmse_df) <- c("model", "rmse_train", "rmse_test")
rmse_df
```

\
**(c)** Based on the results in part (b), write 1-2 sentences discussing which model would you prefer to use for future predictions and why.

> *Model 5 as it is the lowest*

\
**(d)** **(Optional but strongly encouraged)** Make a histogram and boxplot showcasing the distribution of the **effect sizes** over the test data for your preferred model from part (c). As a reminder, the effect size $e_{ij}$ for object $i$ with explanatory variable(s) $x_i \times z_i$ and coefficient $j > 0$ is defined as

$$ e_{ij} = \beta_j \times (x_i \times z_i) $$

such that our linear regression model can be rewritten as 

$$ y_i = \beta_0 + \sum_{j=1}^{m} e_{ij} + \epsilon_i $$


```{r}
# code you answer here

```

Write 1-2 sentences interpreting your results.

> *REPLACE THIS TEXT WITH YOUR ANSWER*